import sys
from argparse import ArgumentParser, Namespace
from typing import Dict

import numpy as np
from torch import nn
from art.estimators.classification import PyTorchClassifier

from src.bin.eval_net_robustness import eval_on_attack, get_attacks
from src.dataset import get_datasets, get_n_classes_and_channels
from src.models.classifiers.model_constructor import get_info_from_path
from src.train import ClassificationModelTrainer


def _parse_args(args) -> Namespace:
    parser = ArgumentParser(description='Simple settings.')
    parser.add_argument('model', help='Path to the model to be attacked.')
    parser.add_argument('target_model', help='Path to the model to be targeted.')
    return parser.parse_args(args)


def eval_net_transfer_robustness(eval_model_trainer: ClassificationModelTrainer,
                                 target_model_trainer: ClassificationModelTrainer,
                                 str_dataset: str,
                                 verbose: bool = True
) -> Dict[str, float]:
    n_classes, n_channels = get_n_classes_and_channels(str_dataset)

    eval_model = PyTorchClassifier(model=eval_model_trainer.model,
                                   loss=nn.CrossEntropyLoss(),
                                   input_shape=(n_channels, 32, 32),
                                   nb_classes=n_classes,
                                   clip_values=(0.0, 1.0))

    target_model = PyTorchClassifier(model=target_model_trainer.model,
                                     loss=nn.CrossEntropyLoss(),
                                     input_shape=(n_channels, 32, 32),
                                     nb_classes=n_classes,
                                     clip_values=(0.0, 1.0))

    dataset = get_datasets(str_dataset.lower())['val']
    clean_val_x = np.stack([x[0].numpy() for x in dataset])
    clean_val_y = np.array([x[1] for x in dataset])

    attacks = get_attacks(target_model, str_dataset)

    adv_accuracies = {}

    for atk_name, attack in attacks.items():
        attack.set_params(verbose=True)
        adv_acc = eval_on_attack(eval_model, attack, clean_val_x, clean_val_y)
        adv_accuracies[atk_name] = adv_acc

        if verbose:
            print(f"Accuracy on adversarial test examples generated by {atk_name}: {adv_acc * 100}%")

    return adv_accuracies


def run(model1_path, model2_path):
    print(model1_path)
    print(model2_path)

    dataset = get_info_from_path(model1_path)[1]

    eval_model_trainer = ClassificationModelTrainer.for_eval(model1_path)
    target_model_trainer = ClassificationModelTrainer.for_eval(model2_path)

    eval_net_transfer_robustness(eval_model_trainer,
                                 target_model_trainer,
                                 dataset,
                                 True)


def main(args=None):
    if args is None:
        args = sys.argv[1:]
    args = _parse_args(args)
    run(args.model, args.target_model)


if __name__ == "__main__":
    main()
